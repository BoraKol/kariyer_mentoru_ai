import streamlit as st # streamlit kullanarak web arayÃ¼zÃ¼ oluÅŸturmak iÃ§in

# from langchain_openai import ChatOpenAI, OpenAIEmbeddings # openai modelleri ve embedding'leri iÃ§in
from langchain_community.vectorstores import FAISS # vektÃ¶r tabanlÄ± arama(semantic search) iÃ§in
from langchain_community.document_loaders import PyPDFLoader # PDF dosyasÄ±nÄ± metne Ã§evirmek iÃ§in
from langchain.text_splitter import RecursiveCharacterTextSplitter # Metni kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rmak iÃ§in
from langchain_community.embeddings import HuggingFaceEmbeddings # huggingface tabanlÄ± embedding modeli
from langchain_together import ChatTogether
from langchain_core.messages import AIMessage , HumanMessage

from dotenv import load_dotenv

import tempfile # geÃ§ici dosyalar oluÅŸturmak iÃ§in
import os 

load_dotenv()

together_key = os.getenv("TOGETHER_AI_API_KEY")
if together_key is None:
    raise ValueError("TOGETHER_AI_API_KEY environment variable is not set.")

# streamlit Sayfa baÅŸlÄ±ÄŸÄ± ve ikon ayarlarÄ±
st.set_page_config(page_title="Kariyer Mentoru AsistanÄ±", page_icon="ðŸ§ ")
st.title("ðŸ§  Kariyer Mentoru AI")
st.write("Bilgilerinizi girin , baÅŸvurmak istediÄŸiniz ilan ve CV'nizin uyumunu Kariyer Mentoru AI deÄŸerlendirsin.")

# Geri bildirim fonksiyonu
def generate_feedback(llm, cv_text, job_text):
    prompt = f"""
    Sen bir kariyer asistanÄ±sÄ±n ve kullanÄ±cÄ±larÄ±n iÅŸ baÅŸvurularÄ±nda en doÄŸru yÃ¶nlendirmeyi saÄŸlamakla gÃ¶revli profesyonel bir danÄ±ÅŸmansÄ±n. 
    AÅŸaÄŸÄ±da kullanÄ±cÄ±ya ait bir Ã¶zgeÃ§miÅŸ (CV) ile baÅŸvurmak istediÄŸi iÅŸ ilanÄ± metni bulunuyor. 

LÃ¼tfen bu bilgiler Ä±ÅŸÄ±ÄŸÄ±nda aÅŸaÄŸÄ±daki sorularÄ± detaylÄ± ve anlaÅŸÄ±lÄ±r ÅŸekilde yanÄ±tla:

CV:
{cv_text}

Ä°ÅŸ Ä°lanÄ±:
{job_text}

Sorular:
1. KullanÄ±cÄ±nÄ±n bu ilana uygunluk seviyesi nedir? Uygunluk oranÄ±nÄ± ve sebeplerini belirt.
2. KullanÄ±cÄ±nÄ±n sahip olmadÄ±ÄŸÄ± ya da zayÄ±f olduÄŸu beceriler hangileridir? BunlarÄ±n neden Ã¶nemli olduÄŸunu aÃ§Ä±kla.
3. CV'nin bu ilana daha uygun hale gelmesi iÃ§in somut Ã¶nerilerde bulun; Ã¶zellikle hangi beceriler, deneyimler veya anahtar kelimeler eklenmeli?
"""

    response =  llm.invoke([HumanMessage(content = prompt)]) 
    return response.content # modelden yanÄ±t alÄ±p sadece iÃ§eriÄŸini dÃ¶ndÃ¼rÃ¼yoruz


# ArayÃ¼z dÃ¼zeni - 1'e 2 oranÄ±nda 2 kolon oluÅŸturalÄ±m
col1, col2 = st.columns([1, 2])

# Sol sÃ¼tun: Girdiler, kullanÄ±cÄ±dan veri alma kÄ±smÄ± 
with col1:
    # st.header("ðŸ“„ Bilgilerinizi Girin") # baÅŸlÄ±k
    uploaded_file = st.file_uploader("CV'nizi yÃ¼kleyin (.pdf)", type="pdf") # kullanÄ±cÄ±dan .pdf formatÄ±nda CV dosyasÄ±nÄ± yÃ¼klemesini istiyoruz
    
    if uploaded_file is not None: # eÄŸer dosya yÃ¼klendiyse , kullanÄ±cÄ±ya baÅŸarÄ±lÄ± mesajÄ± gÃ¶ster
        st.success("CV baÅŸarÄ±yla iÅŸlendi!")
    
    user_input = st.text_area("ðŸ’¼ BaÅŸvurmak istediÄŸiniz iÅŸ ilanÄ±nÄ± buraya yapÄ±ÅŸtÄ±rÄ±n:", height=100) # kullanÄ±cÄ±nÄ±n baÅŸvurmak isteÄŸi ilanÄ± metin kutusuna yazmasÄ± iÃ§in alan
    submit = st.button("ðŸš€ DeÄŸerlendir") # deÄŸerlendirme butonu

# SaÄŸ sÃ¼tun: SonuÃ§larÄ±n , ai asistanÄ±nÄ±n cevabÄ±nÄ±n olduÄŸu sutun ve sohbet gecmisi
with col2:
    if submit: # eger degerlendir butonuna basildiysa
        if uploaded_file is None or not user_input.strip(): # dosya yuklenmemis veya is ilani metni bos birakilmissa uyari goster
            st.warning("LÃ¼tfen hem CVâ€™nizi yÃ¼kleyin hem de iÅŸ ilanÄ± metnini girin.")
        else:
            # PDF dosyasÄ±nÄ± gecici olarak kaydet
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                tmp.write(uploaded_file.read()) # Dosya iÃ§eriÄŸini yaz.
                tmp_path = tmp.name # GeÃ§ici dosya yolunu al 

            # PyPDFLoader ile PDF icerigini okuyup metne donustur
            loader = PyPDFLoader(tmp_path)
            documents = loader.load() # belge listesi olarak doner(sayfa sayfa)

            # Metni kucuk parÃ§alara ayÄ±rmak icin TextSplitter kullanÄ±yoruz
            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
            docs = splitter.split_documents(documents)

            # Embedding olusturmak icin Huggingface'den open source bir embedding modeli kullaniliyor
            embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2") 
            knowledge_base = FAISS.from_documents(docs, embedding) # parcalanmis dokumanlardan vektor veritabani olustur

            # Together dil modeli
            llm = ChatTogether(
                model="mistralai/Mixtral-8x7B-Instruct-v0.1",  # veya birlikte Ã§alÄ±ÅŸtÄ±ÄŸÄ±n baÅŸka bir model
                temperature=0.2,
                max_tokens=1024,
                together_api_key=together_key
            )

            # CV metnini tek bir string haline getiriyoruz
            cv_text = "\n".join([doc.page_content for doc in documents])
            job_text = user_input.strip() # is ilani metni de temizlenip hazir hale getiriliyor

            # Sohbet gecmisi varsa tekrar kullanilmak uzere session_state'e kaydediliyor
            if "chat_history" not in st.session_state:
                st.session_state.chat_history = []

            # dil modelinden geri bildirim alma metodu cagiriliyor ve geri bildirim aliniyor
            response = generate_feedback(llm, cv_text, job_text)

            # kullanicinin girisi ve asistanin cevabi sohbet gecmisine ekleniyor
            st.session_state.chat_history.append(("ðŸ§‘â€ðŸ’¼ CV & Ä°ÅŸ Ä°lanÄ± GÃ¶nderildi", job_text))
            st.session_state.chat_history.append(("ðŸ¤– Kariyer AsistanÄ±", response))

    # Sohbet Gecmisi varsa ekranda gosteriyoruz
    if "chat_history" in st.session_state:
        st.subheader("ðŸ’¬ Sohbet GeÃ§miÅŸi") # gecmis basligi
        
        if st.button("ðŸ§¹ Sohbeti Temizle"): # sohbet gecmisini temizlemek icin bir buton
            st.session_state.chat_history = [] # gecmisi sifirla 
            st.rerun() # sayfayi yeniden yukle 

        for message in st.session_state.chat_history: # sohbet gecmisindeki her mesaji sirayla goster 
            if(message[0] == "ðŸ¤– Kariyer AsistanÄ±"): # burada message yapisi soyle oldugu icin message[0]'a gore filtreledik : message(("ai" , "ai mesaji burada"))
                                                      # message[0] => ai , message[1] ÅŸeklinde bir tuple
                st.markdown(f"**{message[0]}**  : \n\n {message[1]}") # mesaji markdown olarak yazdir 
            
           
